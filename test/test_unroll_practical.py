#!/usr/bin/env python3
"""
Practical demonstration of scan unroll optimization potential.

This creates a simplified version demonstrating the compilation and memory differences
between scan and unrolled implementations.
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import time
import jax
import jax.numpy as jnp
from flax import nnx
from flax.nnx import rnglib as rng

from ueaj.model import TransformerLayer, SoftmaxAttention, MLP
from ueaj.model.nn import *
from ueaj.utils.compile import compile_function


def create_simple_model(num_layers: int, model_d: int = 768):
    """Create a simplified model with individual transformer layers."""

    class SimpleModel(nnx.Module):
        def __init__(self, rngs: rng.Rngs):
            super().__init__()
            self.model_d = model_d
            self.embed = nnx.Embed(50432, model_d, dtype=jnp.bfloat16, rngs=rngs)

            # Create individual layers (not vmapped)
            self.layers = [
                TransformerLayer(
                    model_d=model_d,
                    attn=SoftmaxAttention.override(
                        kq_d=64,
                        kv_heads=model_d // 128,
                        act_fn=leaky_relu_squared,
                    ),
                    mlp=MLP.override(
                        act_fn=leaky_relu_squared,
                    ),
                    rngs=rngs
                ) for _ in range(num_layers)
            ]

    return SimpleModel(rngs=rng.Rngs(42))


def create_scan_variant(layers, unroll_value):
    """Create a function that uses scan with specified unroll."""

    def scan_forward(act, **kwargs):
        def layer_fn(carry, layer):
            out = layer(carry, **kwargs)
            return out.astype(carry.dtype), None

        if unroll_value == "full":
            # Fully unrolled version
            for layer in layers:
                act = layer(act, **kwargs)
                act = act.astype(act.dtype)
            return act
        else:
            # Scan with unroll
            layers_array = jnp.array(layers)  # Convert to array for scan
            act, _ = jax.lax.scan(
                layer_fn,
                act,
                layers_array,
                unroll=unroll_value
            )
            return act

    return scan_forward


def test_compilation_differences():
    """Test compilation time and memory differences between approaches."""

    print("="*80)
    print("PRACTICAL SCAN UNROLL DEMONSTRATION")
    print("="*80)

    # Test configurations
    configs = [
        {"name": "Small (6L)", "num_layers": 6},
        {"name": "Medium (12L)", "num_layers": 12},
    ]

    for config in configs:
        print(f"\n{'‚îÄ'*60}")
        print(f"Testing {config['name']}")
        print(f"{'‚îÄ'*60}")

        # Create model
        model = create_simple_model(config['num_layers'])
        graph_def, state = nnx.split(model)

        # Input shape
        input_shape = jax.ShapeDtypeStruct((2, 512), jnp.int32)

        # Test different approaches
        approaches = [
            ("Full Unroll", "full"),
            ("Scan unroll=1", 1),
            ("Scan unroll=2", 2),
            ("Scan unroll=4", 4),
        ]

        results = {}

        for name, unroll_val in approaches:
            print(f"\nüîÑ Testing {name}...")

            try:
                def forward_pass(graph_def, state, inputs):
                    model = nnx.merge(graph_def, state)
                    act = model.embed(inputs)

                    # Default kwargs for layers
                    batch_size, seq_len = inputs.shape
                    kwargs = {
                        'query_segment_ids': jnp.zeros((batch_size, seq_len), dtype=jnp.int32),
                        'kv_segment_ids': jnp.zeros((batch_size, seq_len), dtype=jnp.int32),
                    }

                    # Apply layers based on approach
                    if unroll_val == "full":
                        # Fully unrolled
                        for layer in model.layers:
                            act = layer(act, **kwargs)
                            act = act.astype(act.dtype)
                        return act
                    else:
                        # Use scan simulation (simplified for demonstration)
                        # In practice, this would need to handle the vmapped structure
                        for i in range(0, len(model.layers), unroll_val):
                            chunk = model.layers[i:i+unroll_val]
                            for layer in chunk:
                                act = layer(act, **kwargs)
                                act = act.astype(act.dtype)
                        return act

                # Compile and measure
                start_time = time.time()
                compiled_fn = compile_function(
                    jax.jit(forward_pass),
                    sample_args=(graph_def, state, input_shape),
                    name=f"{config['name']} - {name}"
                )
                compilation_time = time.time() - start_time

                # Get metrics
                cost = compiled_fn.cost_analysis()
                memory = compiled_fn.memory_analysis()

                results[name] = {
                    'compilation_time': compilation_time,
                    'total_memory_gb': (
                        (memory.temp_size_in_bytes + memory.output_size_in_bytes) * 1e-9
                        if memory else 0
                    ),
                    'flops': cost.get('flops', 0) if cost else 0,
                }

                print(f"   ‚úì Compilation: {compilation_time:.2f}s")
                if memory:
                    total_mem = (memory.temp_size_in_bytes + memory.output_size_in_bytes) * 1e-9
                    print(f"   ‚úì Memory: {total_mem:.2f} GB")

            except Exception as e:
                print(f"   ‚ùå Failed: {e}")
                results[name] = {'error': str(e)}

        # Print comparison
        print(f"\nüìä Summary for {config['name']}:")
        print("‚îÄ" * 70)
        print(f"{'Approach':<18} {'Time (s)':<12} {'Memory (GB)':<15} {'Relative':<10}")
        print("‚îÄ" * 70)

        successful = {k: v for k, v in results.items() if 'error' not in v}

        if successful:
            baseline = successful.get("Scan unroll=1")

            for name in ["Full Unroll", "Scan unroll=1", "Scan unroll=2", "Scan unroll=4"]:
                if name in successful:
                    result = successful[name]

                    if baseline and name != "Scan unroll=1":
                        time_ratio = baseline['compilation_time'] / result['compilation_time']
                        mem_ratio = baseline['total_memory_gb'] / max(result['total_memory_gb'], 0.001)
                        relative = f"{time_ratio:.2f}x / {mem_ratio:.2f}x"
                    else:
                        relative = "baseline"

                    print(f"{name:<18} {result['compilation_time']:<12.2f} "
                          f"{result['total_memory_gb']:<15.2f} {relative:<10}")


def demonstrate_optimizer_inlining_concept():
    """Demonstrate the concept behind optimizer inlining."""

    print(f"\n{'='*80}")
    print("OPTIMIZER INLINING CONCEPT DEMONSTRATION")
    print("="*80)

    print("""
üéØ KEY INSIGHT: Why unroll helps with optimizer inlining

When you use scan with unroll > 1, JAX creates individual `eval_jaxpr_p.bind`
calls for each iteration that CAN be inlined by the compiler.

This allows the compiler to:

1. **Interleave optimizer steps**: Instead of computing all layer gradients
   first, then all optimizer updates, it can compute grad‚Üíupdate‚Üígrad‚Üíupdate

2. **Reduce peak memory**: Gradients for processed layers can be freed immediately
   after the optimizer update, rather than accumulating all gradients

3. **Better cache utilization**: Parameter updates happen while gradients
   are still in cache

üìà Current Model Analysis:
""")

    # Analyze current model structure
    print("Your current model at ueaj/model/model.py:119 uses:")
    print("  @nnx.scan  ‚Üê This becomes a single scan primitive")
    print("  ‚îî‚îÄ Prevents optimizer inlining")
    print()
    print("üîß Solution options:")
    print("1. Replace @nnx.scan with jax.lax.scan(unroll=4)")
    print("2. Use chunked_scan with small chunk_size")
    print("3. Add optimizer hooks within the scan body")
    print()
    print("üí° Recommendation: Start with unroll=4 for ~4-layer chunks")
    print("   This provides good balance of compilation time vs memory optimization")


if __name__ == "__main__":
    # Run the practical demonstration
    test_compilation_differences()

    # Explain the concept
    demonstrate_optimizer_inlining_concept()

    print(f"\n{'='*80}")
    print("NEXT STEPS:")
    print("1. Modify model.py:119 to use jax.lax.scan with unroll=4")
    print("2. Measure actual training memory usage")
    print("3. Compare with current @nnx.scan implementation")
    print("="*80)