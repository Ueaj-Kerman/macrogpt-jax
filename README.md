# MacroGPT-JAX
The purpose of this repository is to implement a highly _configurable_ distributed pretraining script for JAX. 

In opposition to keller's [modded-nanogpt](https://github.com/KellerJordan/modded-nanogpt), the purpose is not nessesarily to be the fastest possible pretraining script. Instead, the following things are prioritized:
 - configurability
 - resilience
 - decent performance (~10% of modded-nanogpt)

It's purpose is to serve as a base for my research projects in optimizers, reinforcement learning among other things.
