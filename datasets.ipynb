{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-10T20:53:45.172058Z",
     "start_time": "2025-11-10T20:53:45.169823Z"
    }
   },
   "source": [
    "import datasets\n",
    "import transformers\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:46:16.645647Z",
     "start_time": "2025-11-10T20:46:06.605890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = datasets.load_dataset(\n",
    "\t\"HuggingFaceFW/fineweb-edu\",\n",
    "\tname=\"sample-10BT\",\n",
    "\tsplit=\"train\",\n",
    "\tstreaming=True,\n",
    ")"
   ],
   "id": "d80cd74ee1d3c77e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T23:53:02.393180Z",
     "start_time": "2025-11-10T23:52:45.056729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for batch in dataset:\n",
    "\tprint(batch['url'])\n",
    "\ttime.sleep(.1)"
   ],
   "id": "d1e81b69b62a2322",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.bbc.co.uk/news/world-latin-america-12292661\n",
      "http://www.mc.vanderbilt.edu/lens/article/?id=110&pg=999\n",
      "http://apod.nasa.gov/apod/ap120623.html\n",
      "http://www.readwritethink.org/about/community-stories/using-think-alouds-inside-36.html\n",
      "http://www.royalty.nu/Europe/England/Stuart/JamesII.html\n",
      "http://www.rwjf.org/en/about-rwjf/program-areas/childhood-obesity/strategy/policy-priority-pricing-strategies.html?t=topics%3A499&t=topics%3A260&t=topics%3A1813\n",
      "http://chnm.gmu.edu/wwh/modules/lesson5/lesson5.php?menu=1&c=strategies&s=0\n",
      "http://www.jhsph.edu/news/news-releases/2012/lee-autism-prevalence.html\n",
      "http://judithlarnerlowry.blogspot.com/2009/02/simplifying-california-native.html\n",
      "http://www.mommytracked.com/node/4457/print\n",
      "http://www.newegg.com/Product/CategoryIntelligenceArticle.aspx?articleId=94\n",
      "http://virtual.cvut.cz/kifb/hindi/concepts/exactly_located.html\n",
      "http://www.artofiaido.com/etiquette\n",
      "http://www.crosswordpuzzlehelp.net/old/dictionary.php?q=Spanish%20nectarine\n",
      "http://www.funderstanding.com/category/child-development/brain-child-development/\n",
      "http://www.indiasurgerytour.com/india-eye-surgery/india-surgery-ptosis-correction.html\n",
      "http://physical-therapy.advanceweb.com/Article/One-Legged-Single-Limb-Stance-Test.aspx\n",
      "http://portsmouthhospital.com/your-health/?/19601/Next\n",
      "http://www.edcc.edu/engr/default.php?showflash=1\n",
      "http://www.flintsciencefair.org/students.php\n",
      "http://www.interfire.org/res_file/fseab_in.asp\n",
      "http://www.sparknotes.com/philosophy/problems/section5.rhtml\n",
      "http://ops.fhwa.dot.gov/freewaymgmt/managed_lanes.htm\n",
      "http://www.fitfortravel.scot.nhs.uk/news/newsdetail/3908.aspx\n",
      "http://ijl.cgpublisher.com/product/pub.30/prod.2349\n",
      "http://phys.org/news/2012-10-reveal-solvent-mixtures-affect-solar.html\n",
      "http://sugarlandheelpain.com/?page_id=78\n",
      "http://www.newscientist.com/article/mg21328484.300-glimpse-elusive-matter-in-shattering-star.html\n",
      "http://www.theatlantic.com/magazine/print/2012/02/assassination/308804/\n",
      "http://www.wupr.org/2010/12/31/when-one-nation-becomes-two/\n",
      "http://differentway4kids.blogspot.com/2010_11_01_archive.html\n",
      "http://earthlingnature.wordpress.com/2012/10/05/friday-fellow-grandidiers-baobab/\n",
      "http://hitzeiyehonatan.blogspot.com/2008_02_01_archive.html\n",
      "http://peakwater.org/2012/02/artificial-glaciers-water-crops-in-indian-highlands/\n",
      "http://www.api.org/news-and-media/hurricane-information/hurricane-preparation.aspx\n",
      "http://www.bookrags.com/lessonplan/the-glory-field/characters.html\n",
      "http://www.mrprintables.com/printable-flash-cards.html\n",
      "http://www.ohiodnr.com/Home/species_a_to_z/redphalarope/tabid/17697/Default.aspx\n",
      "http://www.wisegeek.com/what-is-a-predicate.htm\n",
      "http://ballotpedia.org/wiki/index.php/History_of_Initiative_&_Referendum_in_Arizona\n",
      "http://en.wikibooks.org/wiki/General_Chemistry/Periodicity_and_Electron_Configurations\n",
      "http://everything2.com/user/lesterjane/writeups/cori+spezzati\n",
      "http://googlesystem.blogspot.com/2007/04/google-supercomputer.html?showComment=1176067380000\n",
      "http://everynote.com/orchestralparts.choose/0/58/58/1175.note\n",
      "http://ran.org/protect-an-acre\n",
      "http://www.earthday.org/square-meter\n",
      "http://www.studyphysics.ca/newnotes/20/unit01_kinematicsdynamics/chp04_acceleration/lesson12.htm\n",
      "http://advantagegenealogy.com/blog/2011/03/30/how-do-you-say-genealogy-in-japanese/\n",
      "http://circle.adventist.org/browse/resource.phtml?leaf=3832\n",
      "http://www.al-shia.org/html/eng/page.php?id=167&page=7\n",
      "http://www.econlife.com/tag/refrigeration/\n",
      "http://www.handspeak.com/lit/browse.php?byte=w\n",
      "http://www.sciencedaily.com/releases/2008/05/080519105045.htm\n",
      "http://www.britannica.com/EBchecked/topic/655267/Saint-Zacharias\n",
      "http://www.environmentalgraffiti.com/paleontology/news-nephila-jurassica-golden-orb-weaver-spider-middle-jurassic-discovered-china\n",
      "http://www.history.com/this-day-in-history/cleopatra-commits-suicide\n",
      "http://www.skepdic.com/nkisi.html\n",
      "http://astrogeology.usgs.gov/HotTopics/index.php?/archives/2006/09/14/C26.html\n",
      "http://astrologycritics.com/essential-dignities.html\n",
      "http://blog.geographydirections.com/tag/france/\n",
      "http://fullercenter.org/types-of-builds\n",
      "http://timworstall.com/2010/12/23/on-the-meaning-of-the-word-denis/\n",
      "http://www.cpcwnc.org/resources/toolbox/tips-to-facilitate-workshops-effectively\n",
      "http://www.dlr.de/pf/en/desktopdefault.aspx/tabid-7725/13169_read-33346/\n",
      "http://www.fws.gov/midwest/mussel/highlights/2005_highlight6.html\n",
      "http://www.nagt.org/sp/library/gis/GIS_Barriers.html\n",
      "http://www.resilience.org/stories/2012-10-19/karuk-tribe-learning-from-the-first-californians-for-the-next-california\n",
      "http://www.sullivangoss.com/johnlangley_Howard/\n",
      "http://pondscienceinstitute.on-rev.com/svpwiki/tiki-index.php?page=Tesla%20shield\n",
      "http://starwars.wikia.com/wiki/Freighter\n",
      "http://www.britannica.com/EBchecked/topic/134063/Constantinople-Agreement\n",
      "http://www.countryfile.com/news/bats\n",
      "http://www.efloras.org/florataxon.aspx?flora_id=2&taxon_id=200006547\n",
      "http://www.genengnews.com/gen-news-highlights/scientists-claim-short-amyloid-fibers-are-more-toxic-than-their-longer-counterparts/70115925/?kwrd=Cellular%20Biology\n",
      "http://answers.webmd.com/answers/1195087/how-do-i-treat-mosquito-bites\n",
      "http://hacknmod.com/hack/blow-out-some-led-birthday-candles/\n",
      "http://techbase.kde.org/index.php?title=Contribute/Send_Patches&oldid=40759\n",
      "http://www.bottledwater.org/\n",
      "http://www.h2g2.com/approved_entry/A303346/conversation/view/F37910/T416799\n",
      "http://www.hrmls.com/awright/cgi-bin/aa.fcgi?+ZDFlN2Y2OTY0ZmE3ODBmM2IwM2EwZmFlYTg4MWRhNTISlI0ibvs8tuFLdidYcPWsbrYzAtzw0l6PsmvbEvsSvSHxLc7ZUWfuT%2Fq8jXxxMg2fZvJBI3GsCgqsqB4A6YU2OvgSbvU%3D\n",
      "http://everything2.com/user/KS/writeups/air+pollution\n",
      "http://museumvictoria.com.au/immigrationmuseum/whatson/past-exhibitions/station-pier/?reply=15128&sort=newest&googleminiexclude=1\n",
      "http://www.metaglossary.com/meanings/3337605/\n",
      "http://www.studymode.com/essays/The-Struggle-For-Power-In-The-994323.html\n",
      "http://www.upmc.com/health-library/Pages/ADAM.aspx?GenContentId=003117&ProductId=108&ProjectId=1\n",
      "http://healthyliving.azcentral.com/examples-cardio-weight-training-exercises-6050.html\n",
      "http://ir.lib.uwo.ca/wrrr/4/\n",
      "http://ncpedia.org/print/2268\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m dataset:\n\u001B[32m      2\u001B[39m \t\u001B[38;5;28mprint\u001B[39m(batch[\u001B[33m'\u001B[39m\u001B[33murl\u001B[39m\u001B[33m'\u001B[39m])\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \t\u001B[43mtime\u001B[49m\u001B[43m.\u001B[49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m.1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T23:53:05.239105Z",
     "start_time": "2025-11-10T23:53:05.235381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "current = dataset.state_dict()\n",
    "current"
   ],
   "id": "46128d35190aae8c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "   'shard_example_idx': 1000,\n",
       "   'type': 'ArrowExamplesIterable'},\n",
       "  'previous_state': {'shard_idx': 0,\n",
       "   'shard_example_idx': 0,\n",
       "   'type': 'ArrowExamplesIterable'},\n",
       "  'batch_idx': 95,\n",
       "  'num_chunks_since_previous_state': 95,\n",
       "  'cropped_chunk_length': 0,\n",
       "  'type': 'RebatchedArrowExamplesIterable'},\n",
       " 'epoch': 0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:55:56.776499Z",
     "start_time": "2025-11-10T20:55:52.188374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset.load_state_dict(current)\n",
    "for batch in dataset:\n",
    "\tprint(batch['url'])\n",
    "\ttime.sleep(1)"
   ],
   "id": "7f12e7860b091a19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.bbc.co.uk/news/world-latin-america-12292661\n",
      "http://www.mc.vanderbilt.edu/lens/article/?id=110&pg=999\n",
      "http://apod.nasa.gov/apod/ap120623.html\n",
      "http://www.readwritethink.org/about/community-stories/using-think-alouds-inside-36.html\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[20]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m dataset:\n\u001B[32m      3\u001B[39m \t\u001B[38;5;28mprint\u001B[39m(batch[\u001B[33m'\u001B[39m\u001B[33murl\u001B[39m\u001B[33m'\u001B[39m])\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m \t\u001B[43mtime\u001B[49m\u001B[43m.\u001B[49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T21:08:49.838511Z",
     "start_time": "2025-11-10T21:08:49.831743Z"
    }
   },
   "cell_type": "code",
   "source": "locals()",
   "id": "b6364b4c369e4b3c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__name__': '__main__',\n",
       " '__doc__': 'Automatically created module for IPython interactive environment',\n",
       " '__package__': None,\n",
       " '__loader__': None,\n",
       " '__spec__': None,\n",
       " '__builtin__': <module 'builtins' (built-in)>,\n",
       " '__builtins__': <module 'builtins' (built-in)>,\n",
       " '_ih': ['',\n",
       "  'import datasets\\nimport transformers',\n",
       "  'dataset = datasets.load_dataset(\\n\\t\"HuggingFaceFW/fineweb-edu\",\\n\\tname=\"sample-10BT\",\\n\\tsplit=\"train\",\\n\\tstreaming=True,\\n)',\n",
       "  'dataset.description',\n",
       "  'dataset.state_dict()',\n",
       "  'for batch in dataset:\\n\\tprint(batch)',\n",
       "  'dataset.state_dict()',\n",
       "  'dataset.skip(100_000)',\n",
       "  'dataset.state_dict()',\n",
       "  'dataset.state_dict(), dataset2.state_dict()',\n",
       "  'dataset2 = dataset.skip(1_000_000)',\n",
       "  'dataset.state_dict(), dataset2.state_dict()',\n",
       "  'import datasets\\nimport transformers\\nimport time',\n",
       "  'for batch in dataset:\\n\\tprint(batch)\\n\\ttime.sleep(1)',\n",
       "  'dataset.state_dict()',\n",
       "  \"for batch in dataset:\\n\\tprint(batch['url'])\\n\\ttime.sleep(1)\",\n",
       "  'current = dataset.state_dict()',\n",
       "  'current = dataset.state_dict()\\ncurrent',\n",
       "  \"for batch in dataset:\\n\\tprint(batch['url'])\\n\\ttime.sleep(1)\",\n",
       "  \"dataset.load_state_dict(dataset)\\nfor batch in dataset:\\n\\tprint(batch['url'])\\n\\ttime.sleep(1)\",\n",
       "  \"dataset.load_state_dict(current)\\nfor batch in dataset:\\n\\tprint(batch['url'])\\n\\ttime.sleep(1)\",\n",
       "  'locals()'],\n",
       " '_oh': {3: '',\n",
       "  4: {'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "     'shard_example_idx': 0,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'previous_state': None,\n",
       "    'batch_idx': 0,\n",
       "    'num_chunks_since_previous_state': 0,\n",
       "    'cropped_chunk_length': 0,\n",
       "    'type': 'RebatchedArrowExamplesIterable'},\n",
       "   'epoch': 0},\n",
       "  6: {'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "     'shard_example_idx': 37000,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'previous_state': {'shard_idx': 0,\n",
       "     'shard_example_idx': 36000,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'batch_idx': 36593,\n",
       "    'num_chunks_since_previous_state': 593,\n",
       "    'cropped_chunk_length': 0,\n",
       "    'type': 'RebatchedArrowExamplesIterable'},\n",
       "   'epoch': 0},\n",
       "  7: IterableDataset({\n",
       "      features: ['text', 'id', 'dump', 'url', 'file_path', 'language', 'language_score', 'token_count', 'score', 'int_score'],\n",
       "      num_shards: 14\n",
       "  }),\n",
       "  8: {'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "     'shard_example_idx': 37000,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'previous_state': {'shard_idx': 0,\n",
       "     'shard_example_idx': 36000,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'batch_idx': 36593,\n",
       "    'num_chunks_since_previous_state': 593,\n",
       "    'cropped_chunk_length': 0,\n",
       "    'type': 'RebatchedArrowExamplesIterable'},\n",
       "   'epoch': 0},\n",
       "  11: ({'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "      'shard_example_idx': 37000,\n",
       "      'type': 'ArrowExamplesIterable'},\n",
       "     'previous_state': {'shard_idx': 0,\n",
       "      'shard_example_idx': 36000,\n",
       "      'type': 'ArrowExamplesIterable'},\n",
       "     'batch_idx': 36593,\n",
       "     'num_chunks_since_previous_state': 593,\n",
       "     'cropped_chunk_length': 0,\n",
       "     'type': 'RebatchedArrowExamplesIterable'},\n",
       "    'epoch': 0},\n",
       "   {'examples_iterable': {'examples_iterable': {'skipped': False,\n",
       "      'examples_iterable': {'shard_idx': 0,\n",
       "       'shard_example_idx': 0,\n",
       "       'type': 'ArrowExamplesIterable'},\n",
       "      'type': 'SkipExamplesIterable'},\n",
       "     'previous_state': None,\n",
       "     'batch_idx': 0,\n",
       "     'num_chunks_since_previous_state': 0,\n",
       "     'cropped_chunk_length': 0,\n",
       "     'type': 'RebatchedArrowExamplesIterable'},\n",
       "    'epoch': 0}),\n",
       "  14: {'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "     'shard_example_idx': 1000,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'previous_state': {'shard_idx': 0,\n",
       "     'shard_example_idx': 0,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'batch_idx': 4,\n",
       "    'num_chunks_since_previous_state': 4,\n",
       "    'cropped_chunk_length': 0,\n",
       "    'type': 'RebatchedArrowExamplesIterable'},\n",
       "   'epoch': 0},\n",
       "  17: {'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "     'shard_example_idx': 1000,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'previous_state': {'shard_idx': 0,\n",
       "     'shard_example_idx': 0,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'batch_idx': 7,\n",
       "    'num_chunks_since_previous_state': 7,\n",
       "    'cropped_chunk_length': 0,\n",
       "    'type': 'RebatchedArrowExamplesIterable'},\n",
       "   'epoch': 0}},\n",
       " '_dh': [PosixPath('/mnt/c/Users/devse/IdeaProjects/nanollama')],\n",
       " 'In': ['',\n",
       "  'import datasets\\nimport transformers',\n",
       "  'dataset = datasets.load_dataset(\\n\\t\"HuggingFaceFW/fineweb-edu\",\\n\\tname=\"sample-10BT\",\\n\\tsplit=\"train\",\\n\\tstreaming=True,\\n)',\n",
       "  'dataset.description',\n",
       "  'dataset.state_dict()',\n",
       "  'for batch in dataset:\\n\\tprint(batch)',\n",
       "  'dataset.state_dict()',\n",
       "  'dataset.skip(100_000)',\n",
       "  'dataset.state_dict()',\n",
       "  'dataset.state_dict(), dataset2.state_dict()',\n",
       "  'dataset2 = dataset.skip(1_000_000)',\n",
       "  'dataset.state_dict(), dataset2.state_dict()',\n",
       "  'import datasets\\nimport transformers\\nimport time',\n",
       "  'for batch in dataset:\\n\\tprint(batch)\\n\\ttime.sleep(1)',\n",
       "  'dataset.state_dict()',\n",
       "  \"for batch in dataset:\\n\\tprint(batch['url'])\\n\\ttime.sleep(1)\",\n",
       "  'current = dataset.state_dict()',\n",
       "  'current = dataset.state_dict()\\ncurrent',\n",
       "  \"for batch in dataset:\\n\\tprint(batch['url'])\\n\\ttime.sleep(1)\",\n",
       "  \"dataset.load_state_dict(dataset)\\nfor batch in dataset:\\n\\tprint(batch['url'])\\n\\ttime.sleep(1)\",\n",
       "  \"dataset.load_state_dict(current)\\nfor batch in dataset:\\n\\tprint(batch['url'])\\n\\ttime.sleep(1)\",\n",
       "  'locals()'],\n",
       " 'Out': {3: '',\n",
       "  4: {'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "     'shard_example_idx': 0,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'previous_state': None,\n",
       "    'batch_idx': 0,\n",
       "    'num_chunks_since_previous_state': 0,\n",
       "    'cropped_chunk_length': 0,\n",
       "    'type': 'RebatchedArrowExamplesIterable'},\n",
       "   'epoch': 0},\n",
       "  6: {'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "     'shard_example_idx': 37000,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'previous_state': {'shard_idx': 0,\n",
       "     'shard_example_idx': 36000,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'batch_idx': 36593,\n",
       "    'num_chunks_since_previous_state': 593,\n",
       "    'cropped_chunk_length': 0,\n",
       "    'type': 'RebatchedArrowExamplesIterable'},\n",
       "   'epoch': 0},\n",
       "  7: IterableDataset({\n",
       "      features: ['text', 'id', 'dump', 'url', 'file_path', 'language', 'language_score', 'token_count', 'score', 'int_score'],\n",
       "      num_shards: 14\n",
       "  }),\n",
       "  8: {'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "     'shard_example_idx': 37000,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'previous_state': {'shard_idx': 0,\n",
       "     'shard_example_idx': 36000,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'batch_idx': 36593,\n",
       "    'num_chunks_since_previous_state': 593,\n",
       "    'cropped_chunk_length': 0,\n",
       "    'type': 'RebatchedArrowExamplesIterable'},\n",
       "   'epoch': 0},\n",
       "  11: ({'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "      'shard_example_idx': 37000,\n",
       "      'type': 'ArrowExamplesIterable'},\n",
       "     'previous_state': {'shard_idx': 0,\n",
       "      'shard_example_idx': 36000,\n",
       "      'type': 'ArrowExamplesIterable'},\n",
       "     'batch_idx': 36593,\n",
       "     'num_chunks_since_previous_state': 593,\n",
       "     'cropped_chunk_length': 0,\n",
       "     'type': 'RebatchedArrowExamplesIterable'},\n",
       "    'epoch': 0},\n",
       "   {'examples_iterable': {'examples_iterable': {'skipped': False,\n",
       "      'examples_iterable': {'shard_idx': 0,\n",
       "       'shard_example_idx': 0,\n",
       "       'type': 'ArrowExamplesIterable'},\n",
       "      'type': 'SkipExamplesIterable'},\n",
       "     'previous_state': None,\n",
       "     'batch_idx': 0,\n",
       "     'num_chunks_since_previous_state': 0,\n",
       "     'cropped_chunk_length': 0,\n",
       "     'type': 'RebatchedArrowExamplesIterable'},\n",
       "    'epoch': 0}),\n",
       "  14: {'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "     'shard_example_idx': 1000,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'previous_state': {'shard_idx': 0,\n",
       "     'shard_example_idx': 0,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'batch_idx': 4,\n",
       "    'num_chunks_since_previous_state': 4,\n",
       "    'cropped_chunk_length': 0,\n",
       "    'type': 'RebatchedArrowExamplesIterable'},\n",
       "   'epoch': 0},\n",
       "  17: {'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "     'shard_example_idx': 1000,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'previous_state': {'shard_idx': 0,\n",
       "     'shard_example_idx': 0,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'batch_idx': 7,\n",
       "    'num_chunks_since_previous_state': 7,\n",
       "    'cropped_chunk_length': 0,\n",
       "    'type': 'RebatchedArrowExamplesIterable'},\n",
       "   'epoch': 0}},\n",
       " 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x75f86976f260>>,\n",
       " 'exit': <IPython.core.autocall.ZMQExitAutocall at 0x75f86976f830>,\n",
       " 'quit': <IPython.core.autocall.ZMQExitAutocall at 0x75f86976f830>,\n",
       " 'open': <function _io.open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)>,\n",
       " '_': {'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "    'shard_example_idx': 1000,\n",
       "    'type': 'ArrowExamplesIterable'},\n",
       "   'previous_state': {'shard_idx': 0,\n",
       "    'shard_example_idx': 0,\n",
       "    'type': 'ArrowExamplesIterable'},\n",
       "   'batch_idx': 7,\n",
       "   'num_chunks_since_previous_state': 7,\n",
       "   'cropped_chunk_length': 0,\n",
       "   'type': 'RebatchedArrowExamplesIterable'},\n",
       "  'epoch': 0},\n",
       " '__': {'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "    'shard_example_idx': 1000,\n",
       "    'type': 'ArrowExamplesIterable'},\n",
       "   'previous_state': {'shard_idx': 0,\n",
       "    'shard_example_idx': 0,\n",
       "    'type': 'ArrowExamplesIterable'},\n",
       "   'batch_idx': 4,\n",
       "   'num_chunks_since_previous_state': 4,\n",
       "   'cropped_chunk_length': 0,\n",
       "   'type': 'RebatchedArrowExamplesIterable'},\n",
       "  'epoch': 0},\n",
       " '___': ({'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "     'shard_example_idx': 37000,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'previous_state': {'shard_idx': 0,\n",
       "     'shard_example_idx': 36000,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'batch_idx': 36593,\n",
       "    'num_chunks_since_previous_state': 593,\n",
       "    'cropped_chunk_length': 0,\n",
       "    'type': 'RebatchedArrowExamplesIterable'},\n",
       "   'epoch': 0},\n",
       "  {'examples_iterable': {'examples_iterable': {'skipped': False,\n",
       "     'examples_iterable': {'shard_idx': 0,\n",
       "      'shard_example_idx': 0,\n",
       "      'type': 'ArrowExamplesIterable'},\n",
       "     'type': 'SkipExamplesIterable'},\n",
       "    'previous_state': None,\n",
       "    'batch_idx': 0,\n",
       "    'num_chunks_since_previous_state': 0,\n",
       "    'cropped_chunk_length': 0,\n",
       "    'type': 'RebatchedArrowExamplesIterable'},\n",
       "   'epoch': 0}),\n",
       " '__session__': '/mnt/c/Users/devse/IdeaProjects/nanollama/datasets.ipynb',\n",
       " '_i': \"dataset.load_state_dict(current)\\nfor batch in dataset:\\n\\tprint(batch['url'])\\n\\ttime.sleep(1)\",\n",
       " '_ii': \"dataset.load_state_dict(dataset)\\nfor batch in dataset:\\n\\tprint(batch['url'])\\n\\ttime.sleep(1)\",\n",
       " '_iii': \"for batch in dataset:\\n\\tprint(batch['url'])\\n\\ttime.sleep(1)\",\n",
       " '_i1': 'import datasets\\nimport transformers',\n",
       " 'datasets': <module 'datasets' from '/home/devse/.virtualenvs/nanollama/lib/python3.12/site-packages/datasets/__init__.py'>,\n",
       " 'transformers': <module 'transformers' from '/home/devse/.virtualenvs/nanollama/lib/python3.12/site-packages/transformers/__init__.py'>,\n",
       " '_i2': 'dataset = datasets.load_dataset(\\n\\t\"HuggingFaceFW/fineweb-edu\",\\n\\tname=\"sample-10BT\",\\n\\tsplit=\"train\",\\n\\tstreaming=True,\\n)',\n",
       " 'dataset': IterableDataset({\n",
       "     features: ['text', 'id', 'dump', 'url', 'file_path', 'language', 'language_score', 'token_count', 'score', 'int_score'],\n",
       "     num_shards: 14\n",
       " }),\n",
       " 'sys': <module 'sys' (built-in)>,\n",
       " 'remove_imported_pydev_package': <function pydev_jupyter_utils.remove_imported_pydev_package()>,\n",
       " '_pydevd_bundle': <module '_pydevd_bundle' from '/home/devse/.pycharm_helpers/pydev/_pydevd_bundle/__init__.py'>,\n",
       " 'pydev_jupyter_vars': <module 'pydev_jupyter_vars' from '/home/devse/.pycharm_helpers/jupyter_debug/pydev_jupyter_vars.py'>,\n",
       " '_i3': 'dataset.description',\n",
       " '_3': '',\n",
       " '_i4': 'dataset.state_dict()',\n",
       " '_4': {'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "    'shard_example_idx': 0,\n",
       "    'type': 'ArrowExamplesIterable'},\n",
       "   'previous_state': None,\n",
       "   'batch_idx': 0,\n",
       "   'num_chunks_since_previous_state': 0,\n",
       "   'cropped_chunk_length': 0,\n",
       "   'type': 'RebatchedArrowExamplesIterable'},\n",
       "  'epoch': 0},\n",
       " '_i5': 'for batch in dataset:\\n\\tprint(batch)',\n",
       " 'batch': {'text': 'Network With Us\\nJoin us on Facebook to get the latest news and updates.\\nLauren Boulden\\'s Story\\nUsing Think-Alouds to Get Inside Langston Hughes\\' Head\\nOver my past few years of teaching, there have been multiple occasions where I have been stumped on how to present a particular concept to my students. I\\'ve always been able to turn to ReadWriteThink.org for hands-on, engaging lessons. For example, I knew I wanted my students to develop their skills when it came to interacting with text, particularly with poetry. While searching through the myriad options on ReadWriteThink, I came upon \"Building Reading Comprehension Through Think-Alouds.\"\\nAt first, I planned to use the lesson exactly as written: Read Langston Hughes\\'s poem \"Dream Variation\" and model a think-aloud with students; then have the students try their hand at some think-alouds using other poetry. After working out all of the details, I realized I could develop some additional skills, which would fit perfectly into the scope and sequence of my class. After completing the think-aloud to \"Dream Variation,\" I broke students into selected groups. Each group was given a different Langston Hughes poem and asked to complete a think-aloud. The next day, the students were put into a new jigsaw group where they were solely responsible for sharing what their Langston Hughes poem conveyed. Based on the meanings behind their group mates\\' poems, along with using the knowledge of both their poem and \"Dream Variation,\" students were asked to figure out who Langston Hughes was as a man. What did he stand for? What were his beliefs? What did he want out of life? Students used clues from the various poems to fill in a head-shaped graphic organizer to depict their understanding of who Hughes could be. This simple lesson of working with poems and think-alouds turned into a few days of group communication, text deciphering, inferences, and even an author study!\\nWithout great lessons available on ReadWriteThink.org, such as \"Building Reading Comprehension Through Think-Alouds,\" my students would never have been able to tackle so many key reading strategies in such a short amount of time.\\nGrades 6 – 8 | Lesson Plan | Standard Lesson\\nStudents learn components of think-alouds and type-of-text interactions through teacher modeling. In the process, students develop the ability to use think-alouds to aid in reading comprehension tasks.\\nLauren describes how she used ReadWriteThink in her classroom.\\nI have been teaching seventh- and eighth-grade language arts in Delaware for the past five years. I grew up in Long Island, New York, but have called Delaware my home since completing my undergraduate and master’s work at the University of Delaware. Teaching and learning have become my prime passions in life, which is why my days are spent teaching English, directing plays, organizing the school newspaper, and teaching yoga in the evenings.',\n",
       "  'id': '<urn:uuid:d55ba202-34fa-4fe6-b6ae-698c282eb244>',\n",
       "  'dump': 'CC-MAIN-2013-20',\n",
       "  'url': 'http://www.readwritethink.org/about/community-stories/using-think-alouds-inside-36.html',\n",
       "  'file_path': 's3://commoncrawl/crawl-data/CC-MAIN-2013-20/segments/1368703682988/warc/CC-MAIN-20130516112802-00000-ip-10-60-113-184.ec2.internal.warc.gz',\n",
       "  'language': 'en',\n",
       "  'language_score': 0.9695732593536377,\n",
       "  'token_count': 625,\n",
       "  'score': 3.5625,\n",
       "  'int_score': 4},\n",
       " '_i6': 'dataset.state_dict()',\n",
       " '_6': {'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "    'shard_example_idx': 37000,\n",
       "    'type': 'ArrowExamplesIterable'},\n",
       "   'previous_state': {'shard_idx': 0,\n",
       "    'shard_example_idx': 36000,\n",
       "    'type': 'ArrowExamplesIterable'},\n",
       "   'batch_idx': 36593,\n",
       "   'num_chunks_since_previous_state': 593,\n",
       "   'cropped_chunk_length': 0,\n",
       "   'type': 'RebatchedArrowExamplesIterable'},\n",
       "  'epoch': 0},\n",
       " '_i7': 'dataset.skip(100_000)',\n",
       " '_7': IterableDataset({\n",
       "     features: ['text', 'id', 'dump', 'url', 'file_path', 'language', 'language_score', 'token_count', 'score', 'int_score'],\n",
       "     num_shards: 14\n",
       " }),\n",
       " '_i8': 'dataset.state_dict()',\n",
       " '_8': {'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "    'shard_example_idx': 37000,\n",
       "    'type': 'ArrowExamplesIterable'},\n",
       "   'previous_state': {'shard_idx': 0,\n",
       "    'shard_example_idx': 36000,\n",
       "    'type': 'ArrowExamplesIterable'},\n",
       "   'batch_idx': 36593,\n",
       "   'num_chunks_since_previous_state': 593,\n",
       "   'cropped_chunk_length': 0,\n",
       "   'type': 'RebatchedArrowExamplesIterable'},\n",
       "  'epoch': 0},\n",
       " '_i9': 'dataset.state_dict(), dataset2.state_dict()',\n",
       " '_i10': 'dataset2 = dataset.skip(1_000_000)',\n",
       " 'dataset2': IterableDataset({\n",
       "     features: ['text', 'id', 'dump', 'url', 'file_path', 'language', 'language_score', 'token_count', 'score', 'int_score'],\n",
       "     num_shards: 14\n",
       " }),\n",
       " '_i11': 'dataset.state_dict(), dataset2.state_dict()',\n",
       " '_11': ({'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "     'shard_example_idx': 37000,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'previous_state': {'shard_idx': 0,\n",
       "     'shard_example_idx': 36000,\n",
       "     'type': 'ArrowExamplesIterable'},\n",
       "    'batch_idx': 36593,\n",
       "    'num_chunks_since_previous_state': 593,\n",
       "    'cropped_chunk_length': 0,\n",
       "    'type': 'RebatchedArrowExamplesIterable'},\n",
       "   'epoch': 0},\n",
       "  {'examples_iterable': {'examples_iterable': {'skipped': False,\n",
       "     'examples_iterable': {'shard_idx': 0,\n",
       "      'shard_example_idx': 0,\n",
       "      'type': 'ArrowExamplesIterable'},\n",
       "     'type': 'SkipExamplesIterable'},\n",
       "    'previous_state': None,\n",
       "    'batch_idx': 0,\n",
       "    'num_chunks_since_previous_state': 0,\n",
       "    'cropped_chunk_length': 0,\n",
       "    'type': 'RebatchedArrowExamplesIterable'},\n",
       "   'epoch': 0}),\n",
       " '_i12': 'import datasets\\nimport transformers\\nimport time',\n",
       " 'time': <module 'time' (built-in)>,\n",
       " '_i13': 'for batch in dataset:\\n\\tprint(batch)\\n\\ttime.sleep(1)',\n",
       " '_i14': 'dataset.state_dict()',\n",
       " '_14': {'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "    'shard_example_idx': 1000,\n",
       "    'type': 'ArrowExamplesIterable'},\n",
       "   'previous_state': {'shard_idx': 0,\n",
       "    'shard_example_idx': 0,\n",
       "    'type': 'ArrowExamplesIterable'},\n",
       "   'batch_idx': 4,\n",
       "   'num_chunks_since_previous_state': 4,\n",
       "   'cropped_chunk_length': 0,\n",
       "   'type': 'RebatchedArrowExamplesIterable'},\n",
       "  'epoch': 0},\n",
       " '_i15': \"for batch in dataset:\\n\\tprint(batch['url'])\\n\\ttime.sleep(1)\",\n",
       " '_i16': 'current = dataset.state_dict()',\n",
       " 'current': {'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "    'shard_example_idx': 1000,\n",
       "    'type': 'ArrowExamplesIterable'},\n",
       "   'previous_state': {'shard_idx': 0,\n",
       "    'shard_example_idx': 0,\n",
       "    'type': 'ArrowExamplesIterable'},\n",
       "   'batch_idx': 7,\n",
       "   'num_chunks_since_previous_state': 7,\n",
       "   'cropped_chunk_length': 0,\n",
       "   'type': 'RebatchedArrowExamplesIterable'},\n",
       "  'epoch': 0},\n",
       " '_i17': 'current = dataset.state_dict()\\ncurrent',\n",
       " '_17': {'examples_iterable': {'examples_iterable': {'shard_idx': 0,\n",
       "    'shard_example_idx': 1000,\n",
       "    'type': 'ArrowExamplesIterable'},\n",
       "   'previous_state': {'shard_idx': 0,\n",
       "    'shard_example_idx': 0,\n",
       "    'type': 'ArrowExamplesIterable'},\n",
       "   'batch_idx': 7,\n",
       "   'num_chunks_since_previous_state': 7,\n",
       "   'cropped_chunk_length': 0,\n",
       "   'type': 'RebatchedArrowExamplesIterable'},\n",
       "  'epoch': 0},\n",
       " '_i18': \"for batch in dataset:\\n\\tprint(batch['url'])\\n\\ttime.sleep(1)\",\n",
       " '_i19': \"dataset.load_state_dict(dataset)\\nfor batch in dataset:\\n\\tprint(batch['url'])\\n\\ttime.sleep(1)\",\n",
       " '_i20': \"dataset.load_state_dict(current)\\nfor batch in dataset:\\n\\tprint(batch['url'])\\n\\ttime.sleep(1)\",\n",
       " '_i21': 'locals()'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
